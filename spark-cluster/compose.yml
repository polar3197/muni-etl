services:
  spark-master:
    build: 
      context: .
      dockerfile: master/Dockerfile_pi  # Create this
    container_name: spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=192.168.0.143  # Caddy IP
      - SPARK_PUBLIC_DNS=192.168.0.143   # Caddy IP
      - SPARK_LOCAL_IP=0.0.0.0
    volumes:
      - ./conf/spark-env.sh:/opt/spark/conf/spark-env.sh
      # - /mnt/ssd:/data  # Mount your SSD for data access

  spark-worker:
    build: 
      context: .
      dockerfile: worker/Dockerfile
    container_name: spark-worker
    network_mode: "host"
    ports:
      - "7078:7078"
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_HOST=192.168.0.143  # Caddy IP (same as master)
    volumes:
      - ./conf/spark-env.sh:/opt/spark/conf/spark-env.sh
      - /mnt/ssd:/data  # Access to data